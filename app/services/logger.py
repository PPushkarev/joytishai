import datetime
import os
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv
# framework for worKing with DB
from motor.motor_asyncio import AsyncIOMotorClient

load_dotenv()


# CREATE CLASS FOR WORKING WITH ATLAS DB FOR LOGGING PURPUSE


class MongoAILogger:
    def __init__(self):
        self.uri = os.getenv("MONGO_URI")
        self.client = AsyncIOMotorClient(self.uri)
        self.db = self.client.joytishai_db
        self.collection = self.db.ai_logs

    # Just counting how much we spent for users quires, what we found in Vector base, raw transit data , AI response for counting
    async def log_request(
        self,
        user_query: str,
        retrieved_docs: List[Dict[str, Any]],
        ai_response: Any,
        usage: Dict[str, int],
        formatted_input: Optional[str] = None,  # [OK] –ù–æ–≤–æ–µ –ø–æ–ª–µ
        model_name: str = "gpt-4o-mini",
    ):
        # How much we spent in OpenAI
        p_tokens = usage.get("prompt_tokens", 0)
        c_tokens = usage.get("completion_tokens", 0)

        # Cost of spent
        cost = (p_tokens * 0.15 / 1_000_000) + (c_tokens * 0.60 / 1_000_000)

        log_entry = {
            "timestamp": datetime.datetime.utcnow(),
            "user_query": user_query,
            "formatted_input": formatted_input,  # [OK] –°–æ—Ö—Ä–∞–Ω—è–µ–º
            "context": retrieved_docs,
            "response": ai_response,
            "stats": {"tokens": usage, "cost_usd": cost, "model": model_name},
            "evaluation": {
                "faithfulness": None,
                "relevancy": None,
                "status": "pending",
            },
        }

        result = await self.collection.insert_one(log_entry)
        return result.inserted_id

    # AS a final we ge id record in DB

    # WE USING THIS FUNCTION TO GET INFORMATION FROM RESPONSE FAST API and get to async def log_request

    async def log_analytics(
            self, request, raw_data, final_res, raw_ai_obj, formatted_text=None
    ):
        """INTEGRATION WITH FastAPI"""

        try:
            docs = []

            # --- [FIX] –£–õ–£–ß–®–ï–ù–ù–´–ô –ü–û–ò–°–ö –ö–û–ù–¢–ï–ö–°–¢–ê ---
            # 1. –ï—Å–ª–∏ final_res ‚Äî —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å (dict)
            if isinstance(final_res, dict):
                docs = final_res.get("metadata_context") or final_res.get("context") or []

            # 2. –ï—Å–ª–∏ final_res ‚Äî —ç—Ç–æ Pydantic –æ–±—ä–µ–∫—Ç
            elif hasattr(final_res, "metadata_context"):
                docs = final_res.metadata_context

            # 3. –ï—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ –ø—É—Å—Ç–æ, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤ raw_data (–∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç)
            if not docs and isinstance(raw_data, dict):
                docs = raw_data.get("relevant_texts", [])

            # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ docs ‚Äî —ç—Ç–æ —Å–ø–∏—Å–æ–∫
            if docs is None:
                docs = []
            # ----------------------------------------

            # –ò–∑–≤–ª–µ–∫–∞–µ–º usage –∏–∑ –æ–±—ä–µ–∫—Ç–∞ OpenAI
            if raw_ai_obj and hasattr(raw_ai_obj, "usage"):
                usage_data = {
                    "prompt_tokens": raw_ai_obj.usage.prompt_tokens,
                    "completion_tokens": raw_ai_obj.usage.completion_tokens,
                    "total_tokens": raw_ai_obj.usage.total_tokens,
                }
            else:
                usage_data = {"total_tokens": 0}

            # –ú—ã –ø–µ—Ä–µ–¥–∞–µ–º docs –≤ retrieved_docs, –∞ –≤–Ω—É—Ç—Ä–∏ log_request –æ–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ –ø–æ–ª–µ "context"
            await self.log_request(
                user_query=str(request.chart_data),
                retrieved_docs=docs,
                ai_response=final_res,
                usage=usage_data,
                formatted_input=formatted_text,
            )

            # –ü–æ–ª–µ–∑–Ω—ã–π –ø—Ä–∏–Ω—Ç, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –≤ –∫–æ–Ω—Å–æ–ª–∏ —Å–µ—Ä–≤–µ—Ä–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            print(f"üìù [LOGGER] Logged request. Context items: {len(docs)}")

        except Exception as e:
            print(f"‚ùå Logging error: {e}")

    #  OLD VERSION
    # async def log_analytics(
    #     self, request, raw_data, final_res, raw_ai_obj, formatted_text=None
    # ):
    #     """INTEGRATION WHIT  FastAPI"""
    #
    #     try:
    #         docs = []
    #
    #         # 1. –ü—ã—Ç–∞–µ–º—Å—è –¥–æ—Å—Ç–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ AI (–º—ã –µ–≥–æ —Ç—É–¥–∞ –ø—Ä–∏—Ü–µ–ø–∏–ª–∏ –≤ AIEngine)
    #         if hasattr(final_res, "metadata_context"):
    #             docs = final_res.metadata_context
    #         # 2. –ï—Å–ª–∏ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º –∏–∑ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Å—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–±)
    #         elif isinstance(raw_data, dict):
    #             docs = raw_data.get("relevant_texts", [])
    #
    #         # –ò–∑–≤–ª–µ–∫–∞–µ–º usage –∏–∑ –æ–±—ä–µ–∫—Ç–∞ OpenAI
    #         if raw_ai_obj and hasattr(raw_ai_obj, "usage"):
    #             usage_data = {
    #                 "prompt_tokens": raw_ai_obj.usage.prompt_tokens,
    #                 "completion_tokens": raw_ai_obj.usage.completion_tokens,
    #                 "total_tokens": raw_ai_obj.usage.total_tokens,
    #             }
    #         else:
    #             usage_data = {"total_tokens": 0}
    #
    #         await self.log_request(
    #             user_query=str(request.chart_data),
    #             retrieved_docs=docs,
    #             ai_response=final_res,
    #             usage=usage_data,  # <--- –ó–ê–ü–Ø–¢–£–Æ –î–û–ë–ê–í–ò–õ
    #             formatted_input=formatted_text,  # [OK] –ü–µ—Ä–µ–¥–∞–µ–º –¥–∞–ª—å—à–µ
    #         )
    #     except Exception as e:
    #         print(f"Logging error: {e}")
