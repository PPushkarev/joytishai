import logging
import pandas as pd
from motor.motor_asyncio import AsyncIOMotorClient
from datasets import Dataset
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# –ú–µ—Ç—Ä–∏–∫–∏ Ragas
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy, context_precision
from ragas.llms import LangchainLLMWrapper
from ragas.embeddings import LangchainEmbeddingsWrapper

logger = logging.getLogger(__name__)


# --- –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø (–¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∏–∑ —Ç–µ—Å—Ç–æ–≤ –∏ Allure) ---
_llm = ChatOpenAI(model="gpt-4o", temperature=0)
_emb = OpenAIEmbeddings(model="text-embedding-3-small")

judge_llm = LangchainLLMWrapper(_llm)
judge_embeddings = LangchainEmbeddingsWrapper(_emb)

# –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º —Å—É–¥—å—é –∫ –º–µ—Ç—Ä–∏–∫–∞–º —Å—Ä–∞–∑—É –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –º–æ–¥—É–ª—è
for m in [faithfulness, answer_relevancy, context_precision]:
    m.llm = judge_llm
    if hasattr(m, 'embeddings'):
        m.embeddings = judge_embeddings


async def prepare_ragas_datasets(mongo_uri: str):
    client = AsyncIOMotorClient(mongo_uri)
    db = client.joytishai_db
    collection = db.ai_logs


    # –ë–µ—Ä–µ–º –∑–∞–ø–∏—Å–∏, –æ–∂–∏–¥–∞—é—â–∏–µ –æ—Ü–µ–Ω–∫–∏ (limit 5 –¥–ª—è —Ç–µ—Å—Ç–∞)
    cursor = collection.find({"evaluation.status": "pending"}).limit(5)
    logs = await cursor.to_list(length=5)

    if not logs:
        return None, None, None, collection

    data_tech = {"question": [], "answer": [], "contexts": [], "reference": []}
    data_knowledge = {"question": [], "answer": [], "contexts": [], "reference": []}

    # –í–ê–® –ò–î–ï–ê–õ–¨–ù–´–ô –≠–¢–ê–õ–û–ù
    reference_text = (
        "–°–µ–≥–æ–¥–Ω—è –õ—É–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Å–µ–¥—å–º–æ–º –¥–æ–º–µ, —á—Ç–æ –ø—Ä–∏–Ω–æ—Å–∏—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —ç–º–æ—Ü–∏–∏ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É –≤ –ø–∞—Ä—Ç–Ω–µ—Ä—Å–∫–∏—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö. "
        "–¢—Ä–∞–Ω–∑–∏—Ç–Ω—ã–µ –ø–ª–∞–Ω–µ—Ç—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ –Æ–ø–∏—Ç–µ—Ä, —Ç–∞–∫–∂–µ –∞—Å–ø–µ–∫—Ç–∏—Ä—É—é—Ç –õ—É–Ω—É, —á—Ç–æ —É—Å–∏–ª–∏–≤–∞–µ—Ç —É–¥–∞—á—É –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤ –æ–±—â–µ–Ω–∏–∏ –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–∏ —Å –æ–∫—Ä—É–∂–∞—é—â–∏–º–∏. "
        "–í —Ç–æ –∂–µ –≤—Ä–µ–º—è, –°–æ–ª–Ω—Ü–µ, –ú–∞—Ä—Å –∏ –ú–µ—Ä–∫—É—Ä–∏–π –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ —à–µ—Å—Ç–æ–º –¥–æ–º–µ, —á—Ç–æ –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ –≤ —Å–ª—É–∂–±–µ –∏ –∑–¥–æ—Ä–æ–≤—å–µ, —Ç—Ä–µ–±—É—é—â–∏–µ –≤–Ω–∏–º–∞–Ω–∏—è. "
        "–°–∏–ª—å–Ω—ã–µ –¥–æ–º–∞: –ß–µ—Ç–≤–µ—Ä—Ç—ã–π –¥–æ–º, —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –∫–æ–º—Ñ–æ—Ä—Ç–æ–º, –∏ –î–µ–≤—è—Ç—ã–π –¥–æ–º ‚Äî —É–¥–∞—á–∞. "
        "–°–ª–∞–±—ã–µ –¥–æ–º–∞: –ü—è—Ç—ã–π –¥–æ–º (—Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ) –∏ –í–æ—Å—å–º–æ–π –¥–æ–º (–∫—Ä–∏–∑–∏—Å—ã). "
        "–ú—É–¥—Ä–æ—Å—Ç—å: –ü—è—Ç—ã–π –∏ –¥–µ–≤—è—Ç—ã–π –¥–æ–º–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –º–∏–ª–æ—Å—Ç—å –∏ —É–¥–∞—á—É ‚Äì —Ö–æ—Ä–æ—à—É—é –∫–∞—Ä–º—É. "
        "–î–µ–≤—è—Ç—ã–π –¥–æ–º —Å–≤—è–∑–∞–Ω —Å —É–¥–∞—á–µ–π –æ—Å–æ–±—ã–º –æ–±—Ä–∞–∑–æ–º (–ª–æ—Ç–µ—Ä–µ–∏, –≤–µ–∑–µ–Ω–∏–µ). "
        "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Å–µ–º–µ–π–Ω—ã–º —Ü–µ–Ω–Ω–æ—Å—Ç—è–º (4) –∏ –¥—É—Ö–æ–≤–Ω—ã–º –ø—Ä–∞–∫—Ç–∏–∫–∞–º (9), —á—Ç–æ–±—ã –ø—Ä–µ–æ–¥–æ–ª–µ—Ç—å —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ –≤ —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–µ (5) –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è—Ö (8)."
    )

    for log in logs:
        user_query = str(log.get("user_query", ""))
        response_obj = log.get("response", {})
        answer = response_obj.get("astrological_analysis", "") if isinstance(response_obj, dict) else str(response_obj)

        # ü™ê –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç
        data_tech["question"].append(user_query)
        data_tech["answer"].append(answer)
        data_tech["contexts"].append([user_query])
        data_tech["reference"].append(user_query)

        # üìö –ö–æ–Ω—Ç–µ–Ω—Ç–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç (RAG)
        data_knowledge["question"].append(user_query)
        data_knowledge["answer"].append(answer)

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ª–æ–≥–∞
        raw_context = log.get("context", [])
        cleaned_context = [
            item.get("page_content") if isinstance(item, dict) else str(item)
            for item in raw_context
        ]

        # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—É—Å—Ç, Ragas –≤—ã–¥–∞—Å—Ç 0. –î–ª—è —Ç–µ—Å—Ç–∞ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ñ–µ–π–∫,
        # –Ω–æ –¥–ª—è –∂–∏–∑–Ω–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –∏–∑ –ë–î:
        data_knowledge["contexts"].append(cleaned_context if cleaned_context else ["–ü—É—Å—Ç–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"])
        data_knowledge["reference"].append(reference_text)

    return Dataset.from_dict(data_tech), Dataset.from_dict(data_knowledge), logs, collection


async def execute_ragas_cycle(mongo_uri: str):
    logger.info("üë®‚Äç‚öñÔ∏è [RAGAS] –ó–∞–ø—É—Å–∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏—Ç–∞ (RU –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω)...")

    ds_tech, ds_knowledge, logs, collection = await prepare_ragas_datasets(mongo_uri)

    if not ds_tech:
        return {"status": "idle"}

    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ò–ò-—Å—É–¥—å–∏
        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

        judge_llm = LangchainLLMWrapper(llm)
        judge_emb = LangchainEmbeddingsWrapper(embeddings)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–µ—Ç—Ä–∏–∫ (–ø—Ä–∏–≤—è–∑—ã–≤–∞–µ–º LLM –∫ –∫–∞–∂–¥–æ–π)
        metrics = [faithfulness, answer_relevancy, context_precision]
        for m in metrics:
            m.llm = judge_llm
            if hasattr(m, 'embeddings'):
                m.embeddings = judge_emb

        # 1. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞
        results_tech = evaluate(dataset=ds_tech, metrics=[faithfulness], llm=judge_llm,
                                embeddings=judge_emb).to_pandas()

        # 2. –ö–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        results_know = evaluate(dataset=ds_knowledge, metrics=metrics, llm=judge_llm, embeddings=judge_emb).to_pandas()

        # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        for i, log in enumerate(logs):
            res_t = results_tech.iloc[i]
            res_k = results_know.iloc[i]

            await collection.update_one(
                {"_id": log["_id"]},
                {"$set": {
                    "evaluation.technical_faithfulness": float(res_t.get("faithfulness", 0)),
                    "evaluation.knowledge_faithfulness": float(res_k.get("faithfulness", 0)),
                    "evaluation.relevancy": float(res_k.get("answer_relevancy", 0)),
                    "evaluation.context_precision": float(res_k.get("context_precision", 0)),
                    "evaluation.status": "evaluated",
                    "evaluation.engine": "ragas_ru_v2"
                }}
            )

        return {"status": "success", "processed": len(logs)}

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ Ragas: {e}")
        return {"status": "error", "message": str(e)}