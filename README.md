# JyotishAI Interpretation Service
![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-05998b.svg)
![OpenAI](https://img.shields.io/badge/AI-GPT--4o-orange.svg)
![ChromaDB](https://img.shields.io/badge/VectorDB-Chroma-red.svg)
![MongoDB](https://img.shields.io/badge/NoSQL-MongoDB-47A248.svg)
![CI Status](https://github.com/PPushkarev/JYOTISHAPI/actions/workflows/tests.yml/badge.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)
![Tests](https://img.shields.io/badge/Tests-Passing-brightgreen.svg)
![Railway](https://img.shields.io/badge/Deployed%20on-Railway-black.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)

A professional microservice for interpreting Vedic (Jyotish) horoscopes. The system utilizes **RAG (Retrieval-Augmented Generation)** to analyze planetary transits based on classical scriptures and modern astrological expertise.

---

## Key Features & Engineering Highlights

* **üõ° Robust RAG Pipeline**:
    * **Noise Reduction**: Implemented a custom regex-based cleaning layer to strip artifacts (headers, page numbers) from unstructured PDF data before context injection.
    * **Semantic Alignment**: Optimized vector search queries to bridge the language gap between technical code and Russian Vedic scriptures.

* ** Chain-of-Thought Synthesis**:
    * **"Leverage Strategy" Logic**: The AI doesn't just list planetary positions; it identifies the *Weakest House* (Risk) and generates a strategic remedy using the *Strongest Houses* (Resources) as a support mechanism.
    * **Negative Constraints Prompting**: Strict system instructions prevent "hallucinations" (e.g., merging planets into wrong houses) and enforce qualitative descriptions over raw numerical scores.

* ** Intelligent Orchestration**:
    * Acts as the system's "brain," coordinating data from the Astro Engine and synthesizing it into human-readable advice using **OpenAI JSON Mode**.
    * **Resilience Layer**: Built-in retry logic and error handling to prevent crashes when external APIs or Vector DBs are temporarily unavailable.

* ** Analytics Deep-Dive**: Stores the full "thought process" (Raw Prompt vs. Output) in MongoDB for continuous prompt engineering and fine-tuning.
---

##  System Architecture & Ecosystem

This service is the **Central Orchestrator** of the Astroparamita platform. It bridges the gap between raw astronomical math and human-centric spiritual guidance.

###  Ecosystem Integration

![System Architecture](./docs/astroparamitaall.jpg)

1. **Input**: Receives a request from the **Astroparamita Bot**.
2. **Data Fetching**: Calls the **Transit Engine API (Core)** to get high-precision planetary positions and scores.
3. **Context Enrichment**: Performs a similarity search in **ChromaDB** to find relevant interpretations from classical scriptures.
4. **Synthesis**: Sends the combined data (Astro data + Scripture context) to **OpenAI GPT-4o**.
5. **Output**: Delivers a structured, validated interpretation back to the Bot.

### Related Repositories:
*  [**Astroparamita Bot**](https://github.com/PPushkarev/astroparamitabot) ‚Äî Telegram Client Interface.
*  [**JyotishAPI**](https://github.com/PPushkarev/JYOTISHAPI.git) ‚Äî Transit Engine API (Core).

---

## Tech Stack

* **Framework**: FastAPI (Python 3.11+)
* **AI/LLM**: OpenAI GPT-4o / LangChain
* **Vector DB**: ChromaDB (for RAG context)
* **Database**: MongoDB (for analytics and logging)
* **Testing**: Pytest (Asyncio-based)
* **Deployment**: Docker, Railway, GitHub Actions (CI/CD)

---

## Project Structure

* **app/**: Main application package.
    * **main.py**: FastAPI entry point and endpoint orchestration.
    * **services/**: Business logic (AI Engine, Astro Client, Vector Store, Logger).
    * **schemas/**: Pydantic models for request/response validation.
* **tests/**: Automated unit and integration test suite.
* **.github/workflows/**: CI/CD pipeline configuration (Automated testing & deployment).
* **Dockerfile**: Container configuration.
* **Procfile**: Deployment command for Railway.
* **entrypoint.sh**: Startup script for sequential execution (Indexing -> Server).


## Testing Architecture & Directory Structure

–ü—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥—É–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–µ—Å—Ç–æ–≤, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—É—é –ø–æ —É—Ä–æ–≤–Ω—è–º –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ (Unit, Integration, E2E) –∏ —Ç–∏–ø–∞–º –∞—É–¥–∏—Ç–∞ (Security, RAG, Logic).

```text
tests/
‚îú‚îÄ‚îÄ conftest.py                # Shared fixtures (HTTP clients, DB mocks, ENV loading)
‚îú‚îÄ‚îÄ test_api_consultation.py   # End-to-End: Full cycle verification from request to final output
‚îú‚îÄ‚îÄ test_security.py           # Security & Red Teaming: Jailbreak and Prompt Leakage attacks
‚îú‚îÄ‚îÄ test_reasoning.py          # Logic & CoT: Chain-of-Thought and instruction following audit
‚îú‚îÄ‚îÄ test_main.py               # Unit Tests for main functions of Engine 
‚îú‚îÄ‚îÄ test_rag.py                # Infrastructure: ChromaDB audit, PDF ingestion, and metadata
‚îú‚îÄ‚îÄ test_api.py                # Integration Tests for connections Resilience: handling of 502/504 errors and API timeouts
‚îî‚îÄ‚îÄ test_rag_quality.py        # RAG Quality: Automated Faithfulness and Relevancy evaluation
```
## AI Test Suite and Engineering Excellence

This project implements a multi-layered automated testing framework using **Pytest** and **Allure**, covering the entire AI lifecycle from raw data validation to deep semantic reasoning.

### 1. End-to-End System Integration (E2E)
* **Full Flow Validation**: Verifies the complete data journey: *User Input -> Transit Engine (External API) -> ChromaDB (Vector Search) -> OpenAI (Synthesis) -> Final Client Response*.
* **Response Schema Integrity**: Enforces strict adherence to Pydantic JSON schemas, specifically validating mandatory blocks: `astrological_analysis`, `classic_wisdom`, and `recommendations`.



### 2. AI Safety and Red Teaming (Security)
* **Jailbreak Defense**: Automated adversarial attacks (e.g., "Pirate Attack") verify that the model cannot be forced to abandon its professional persona or use prohibited language.
* **System Prompt Leakage**: Explicit tests to ensure internal configuration and proprietary system instructions remain hidden from the end-user.
* **Ethical Guardrails**: Built-in safety checks to confirm the AI refuses to provide medical diagnoses, fatalistic predictions (e.g., exact date of death), or display gender bias.



### 3. Infrastructure and Resilience
* **Mocking and Isolation**: Utilizes `unittest.mock` to simulate external API timeouts and OpenAI server failures, ensuring the system handles "Bad Gateway" (502/504) errors gracefully.
* **Vector Store Audit**: Dedicated tests for ChromaDB ensure PDF files are correctly ingested, metadata is preserved, and duplicate documents are automatically skipped.
* **Pydantic Edge Cases**: Validation tests for empty payloads and corrupted astrological data to prevent 500-series server errors.

### 4. Semantic and Logic Verification (CoT)
* **Chain-of-Thought Audit**: Instead of simple keyword matching, the suite uses **Semantic Parsing** to verify that the AI's internal reasoning followed the correct planetary logic.
* **Instruction Following**: Automated tracking of the model's ability to respect user-defined output constraints (e.g., step-by-step breakdown) versus hard-coded system instructions.




---

### Quality Metrics Dashboard (Allure)
The testing process generates detailed Allure reports, providing visibility into:
* **Test Severity**: Categorization of security and logic tests.
* **Historical Trends**: Tracking model reliability over multiple iterations.
* **Attachment Analysis**: Storage of raw AI "thought logs" for debugging failed logic chains.

![Allure Report Dashboard](./docs/allure_report.jpg)

---
## API Preview

<details>
  <summary>Click to view Swagger UI Screenshots</summary>

  ### AI Generation Endpoint
  ![Swagger Overview](./docs/swagger.jpg)

  ### Structured AI Response (The "Wow" factor)
  ![AI Response](./docs/response.jpg)
  
  *Example of how raw data is transformed into professional astrological analysis.*

  ### Data Schemas
  ![AI Schemas](./docs/schemas.jpg)

</details>

---


## Interactive API Documentation

### Production (Live Server)
The service is deployed and running the AI orchestration engine:
- **Swagger UI**: [https://web-production-991f4.up.railway.app/docs](https://web-production-991f4.up.railway.app/docs)
- **ReDoc**: [https://web-production-991f4.up.railway.app/redoc](https://web-production-991f4.up.railway.app/redoc)
- **Health Status**: `Active` ‚úÖ

### Local Development
To access the documentation on your local machine after startup:
- **Swagger UI**: [http://localhost:8000/docs](http://localhost:8000/docs)
- **ReDoc**: [http://localhost:8000/redoc](http://localhost:8000/redoc)

---

To quickly test the API in Swagger UI, you can use this sample payload:
```json
{
  "user_id": 500123445,
  "chart_data": {
    "name": "–°–æ–±–∞–∫–∞",
    "date": "1980-03-14",
    "time": "17:30",
    "city": "–ò—Ä–∫—É—Ç—Å–∫",
    "latitude": 52.286,
    "longitude": 104.2807,
    "timezone": "Asia/Irkutsk",
    "utc_offset": 8.0,
    "julian_day": 2444312.89583,
    "lagna": 134.77,
    "sign": "–õ–µ–≤",
    "planets": {
      "–õ–∞–≥–Ω–∞": {
        "degree": "14¬∞46'28''",
        "sign": "–õ–µ–≤",
        "house": 1,
        "nakshatra": "–ü—É—Ä–≤–∞-–ü—Ö–∞–ª–≥—É–Ω–∏",
        "pada": 1,
        "nakshatra_lord": "–í–µ–Ω–µ—Ä–∞",
        "retrograde": false,
        "display_name": "–õ–∞–≥–Ω–∞"
      },
      "–°–æ–ª–Ω—Ü–µ": {
        "degree": "0¬∞22'44''",
        "sign": "–†—ã–±—ã",
        "house": 8,
        "nakshatra": "–ü—É—Ä–≤–∞-–ë—Ö–∞–¥—Ä–∞–ø–∞–¥–∞",
        "pada": 4,
        "nakshatra_lord": "–Æ–ø–∏—Ç–µ—Ä",
        "retrograde": false,
        "display_name": "–°–æ–ª–Ω—Ü–µ"
      },
      "–õ—É–Ω–∞": {
        "degree": "26¬∞43'38''",
        "sign": "–ö–æ–∑–µ—Ä–æ–≥",
        "house": 6,
        "nakshatra": "–î—Ö–∞–Ω–∏—à—Ç—Ö–∞",
        "pada": 2,
        "nakshatra_lord": "–ú–∞—Ä—Å",
        "retrograde": false,
        "display_name": "–õ—É–Ω–∞",
        "longitude": 26.72722222222222
      },
      "–ú–∞—Ä—Å": {
        "degree": "5¬∞39'9''",
        "sign": "–õ–µ–≤",
        "house": 1,
        "nakshatra": "–ú–∞–≥—Ö–∞",
        "pada": 2,
        "nakshatra_lord": "–ö–µ—Ç—É",
        "retrograde": true,
        "display_name": "–ú–∞—Ä—Å R"
      },
      "–ú–µ—Ä–∫—É—Ä–∏–π": {
        "degree": "15¬∞13'5''",
        "sign": "–í–æ–¥–æ–ª–µ–π",
        "house": 7,
        "nakshatra": "–®–∞—Ç–∞–±—Ö–∏—à–∞",
        "pada": 3,
        "nakshatra_lord": "–†–∞—Ö—É",
        "retrograde": true,
        "display_name": "–ú–µ—Ä–∫—É—Ä–∏–π R"
      },
      "–Æ–ø–∏—Ç–µ—Ä": {
        "degree": "9¬∞21'28''",
        "sign": "–õ–µ–≤",
        "house": 1,
        "nakshatra": "–ú–∞–≥—Ö–∞",
        "pada": 3,
        "nakshatra_lord": "–ö–µ—Ç—É",
        "retrograde": true,
        "display_name": "–Æ–ø–∏—Ç–µ—Ä R"
      },
      "–í–µ–Ω–µ—Ä–∞": {
        "degree": "14¬∞54'20''",
        "sign": "–û–≤–µ–Ω",
        "house": 9,
        "nakshatra": "–ë—Ö–∞—Ä–∞–Ω–∏",
        "pada": 1,
        "nakshatra_lord": "–í–µ–Ω–µ—Ä–∞",
        "retrograde": false,
        "display_name": "–í–µ–Ω–µ—Ä–∞"
      },
      "–°–∞—Ç—É—Ä–Ω": {
        "degree": "0¬∞2'39''",
        "sign": "–î–µ–≤–∞",
        "house": 2,
        "nakshatra": "–£—Ç—Ç–∞—Ä–∞-–ü—Ö–∞–ª–≥—É–Ω–∏",
        "pada": 2,
        "nakshatra_lord": "–°–æ–ª–Ω—Ü–µ",
        "retrograde": true,
        "display_name": "–°–∞—Ç—É—Ä–Ω R"
      },
      "–†–∞—Ö—É": {
        "degree": "4¬∞25'44''",
        "sign": "–õ–µ–≤",
        "house": 1,
        "nakshatra": "–ú–∞–≥—Ö–∞",
        "pada": 2,
        "nakshatra_lord": "–ö–µ—Ç—É",
        "retrograde": true,
        "display_name": "–†–∞—Ö—É R"
      },
      "–ö–µ—Ç—É": {
        "degree": "4¬∞25'44''",
        "sign": "–í–æ–¥–æ–ª–µ–π",
        "house": 7,
        "nakshatra": "–î—Ö–∞–Ω–∏—à—Ç—Ö–∞",
        "pada": 4,
        "nakshatra_lord": "–ú–∞—Ä—Å",
        "retrograde": true,
        "display_name": "–ö–µ—Ç—É R"
      }
    }
  },
  "transit_date": "2026-01-02",
  "language": "ru"
}
```


## Quick Start
### Development Commands (Makefile)

The project includes a `Makefile` to simplify common development tasks. 

* **Install dependencies**: `make install`
* **Run full system**: `make run` (Triggers indexing and starts the server)
* **Rebuild Knowledge Base**: `make index` (Updates the ChromaDB vector store)
* **Execute Tests**: `make test` (Runs End-to-End integration tests)
* **Cleanup**: `make clean` (Removes cache and temporary files)
* **Fast Deploy**: `make deploy` (Cleans, updates requirements, and pushes to GitHub)
* 
###  Environment Configuration
Create a `.env` file in the root directory:
```env

OPENAI_API_KEY: Your secret key from OpenAI, used to authorize GPT-4o requests for horoscope generation. 
OPENAI_MODEL: The specific AI model version used by the service, such as gpt-4o. 
AI_TEMPERATURE: Controls the balance between factual and creative AI responses; lower values ensure more consistent astrological logic. 
MONGO_URI: The full connection string for your MongoDB database, used for background logging and analytics storage. 
API_AUTH_TOKEN: A private security token used to authenticate and protect your API endpoints from unauthorized access. 
TEST_API_URL: The base URL used by the automated test suite to verify the service status, usually http://127.0.0.1:8000. 
ANALYZE_ENDPOINT: The internal path for the interpretation logic, specifically /api/v1/forecast/generate. 
ASTRO_ENGINE_URL: The URL of the external Astro Engine service that calculates planetary positions and house points. 
ASTRO_CALCULATE_ENDPOINT: The specific remote endpoint used to fetch technical transit data from the Astro Engine. 
PYTHONPATH: Set to the root directory to ensure the system correctly finds and imports your application modules. 
PORT: The network port the server listens on, which is automatically assigned in production environments like Railway.